{"metadata":{"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mapping = pd.read_csv(\"/kaggle/input/twitter-emoji-prediction/Mapping.csv\")\ntrain = pd.read_csv(\"/kaggle/input/twitter-emoji-prediction/Train.csv\")\ntest = pd.read_csv(\"/kaggle/input/twitter-emoji-prediction/Test.csv\")\nout = pd.read_csv(\"/kaggle/input/twitter-emoji-prediction/OutputFormat.csv\")","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mapping = mapping.drop(['Unnamed: 0'], axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emoticons = mapping['emoticons'].tolist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mapp = {}\nfor emo in range(0,len(emoticons)):\n    mapp[emo]= emoticons[emo]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mapp","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.drop(['Unnamed: 0'], axis = 1)\ntest = test.drop(['Unnamed: 0'], axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train = train['TEXT'].values\ny_train = train['Label'].values\n\nx_test = test['TEXT'].values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train.shape, x_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## embed","metadata":{}},{"cell_type":"code","source":"f = open(\"../input/glovetxt/glove.6B.50d.txt\", encoding='utf8')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_index = {}\n\nfor line in f:\n    values = line.split()\n    word = values[0]\n    emb = np.array(values[1:], dtype ='float')\n    embedding_index[word] = emb","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_index['america'].shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_embedding_output(X):\n    maxLen = 20\n    embedding_output = np.zeros((len(X), maxLen, 50))\n    \n    for ix in range(X.shape[0]):\n        my_example = X[ix].split()\n        \n#         print(my_example)       \n        for ij in range(len(my_example)): \n            if (embedding_index.get(my_example[ij].lower()) is not None) and (ij<maxLen):\n                embedding_output[ix][ij] = embedding_index[my_example[ij].lower()]\n            \n    return embedding_output","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train_embed = get_embedding_output(x_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train_embed.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.utils import to_categorical","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = to_categorical(y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train[1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SMOTE","metadata":{}},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train_embed.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train_embed = x_train_embed.reshape(-1, 1000)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oversample = SMOTE()\nX, y = oversample.fit_resample(x_train_embed, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = X.reshape(-1, 20, 50)\nX.shape, y.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Split","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x1, x2, y1, y2 = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for i in range(0, 5):\n#     print(x_train[i], mapp[y_train[i]])\nx1.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## *LSTM*","metadata":{}},{"cell_type":"code","source":"from keras.models import Sequential \nfrom keras.layers import LSTM, Dense, Dropout, Bidirectional","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Bidirectional(LSTM(units = 512, return_sequences=True), input_shape = (20,50)))\nmodel.add(Dropout(0.3))\nmodel.add(Bidirectional(LSTM(units=256)))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(units=128, activation='relu'))\nmodel.add(Dense(units=64, activation='relu'))\nmodel.add(Dense(units=32, activation='relu'))\nmodel.add(Dense(units=20, activation='softmax'))\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics =['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist = model.fit(x1, y1, validation_split=0.2, shuffle=True, batch_size=64, epochs=25)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(x2, y2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}